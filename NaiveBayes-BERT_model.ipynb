{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qPKYjF5N1sp"
   },
   "source": [
    "# \"Quora Questions Pairs using BERT\"\n",
    "> \"Task: Identify wether two question have similar context/meaning or not\"\n",
    "\n",
    "- toc: true\n",
    "- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- categories: [fastpages, jupyter]\n",
    "- image: images/some_folder/your_image.png\n",
    "- hide: false\n",
    "- search_exclude: true\n",
    "- metadata_key1: metadata_value1\n",
    "- metadata_key2: metadata_value2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zDHKLvx7CU6U"
   },
   "source": [
    "### Quora Questions Pairs using BERT : Overview\n",
    "\n",
    "**Task: Identify wether two question have similar context/meaning or not**<br>\n",
    "[kaggle](https://www.kaggle.com/c/quora-question-pairs/overview)\n",
    "<br>\n",
    "I have tried this problem using two different approach\n",
    "\n",
    "\n",
    "1.   Using Naive Bayes Classifier\n",
    "2.   Using BERT\n",
    "\n",
    "### Naive Bayes Classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ZlQy8-Hekb5q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "path = \"quora-question-pairs\"\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "K1JfbFe3koUP",
    "outputId": "4b58a1f8-bc04-45b3-cc99-6203ca8c3f9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples: 404290\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>How can I increase the speed of my internet co...</td>\n",
       "      <td>How can Internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>Why am I mentally very lonely? How can I solve...</td>\n",
       "      <td>Find the remainder when [math]23^{24}[/math] i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>Which one dissolve in water quikly sugar, salt...</td>\n",
       "      <td>Which fish would survive in salt water?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>Should I buy tiago?</td>\n",
       "      <td>What keeps childern active and far from phone ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>When do you use シ instead of し?</td>\n",
       "      <td>When do you use \"&amp;\" instead of \"and\"?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
       "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "2   2     5     6  How can I increase the speed of my internet co...   \n",
       "3   3     7     8  Why am I mentally very lonely? How can I solve...   \n",
       "4   4     9    10  Which one dissolve in water quikly sugar, salt...   \n",
       "5   5    11    12  Astrology: I am a Capricorn Sun Cap moon and c...   \n",
       "6   6    13    14                                Should I buy tiago?   \n",
       "7   7    15    16                     How can I be a good geologist?   \n",
       "8   8    17    18                    When do you use シ instead of し?   \n",
       "9   9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  What is the step by step guide to invest in sh...             0  \n",
       "1  What would happen if the Indian government sto...             0  \n",
       "2  How can Internet speed be increased by hacking...             0  \n",
       "3  Find the remainder when [math]23^{24}[/math] i...             0  \n",
       "4            Which fish would survive in salt water?             0  \n",
       "5  I'm a triple Capricorn (Sun, Moon and ascendan...             1  \n",
       "6  What keeps childern active and far from phone ...             0  \n",
       "7          What should I do to be a great geologist?             1  \n",
       "8              When do you use \"&\" instead of \"and\"?             0  \n",
       "9  How do I hack Motorola DCX3400 for free internet?             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load Data\n",
    "train = pd.read_csv(path+\"/train.csv\")\n",
    "print(\"Total samples:\",len(train))\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPLogC5t22AY",
    "outputId": "20c4587e-6c88-4d8a-a056-84fab8943b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              0\n",
      "qid1            0\n",
      "qid2            0\n",
      "question1       1\n",
      "question2       2\n",
      "is_duplicate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#dropping null values\n",
    "print(train.isnull().sum(axis=0))\n",
    "train.dropna(axis=0,inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sY9wDKyOFDlT"
   },
   "source": [
    "#### Text Preprocessing\n",
    "\n",
    "*   remove stopwords\n",
    "*   Lemmatize similar words \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "n9r3xbLrm_RN"
   },
   "outputs": [],
   "source": [
    "#preprocessing\n",
    "def preprocess(series):\n",
    "  #remove characters other than alphabets & numerics\n",
    "  words = re.sub(\"[^A-Za-z0-9]\",\" \",series).lower().split()\n",
    "\n",
    "  #lemmatize words\n",
    "  lemm = WordNetLemmatizer()\n",
    "  stpwords = stopwords.words('english')\n",
    "  lemmitized = [lemm.lemmatize(word) for word in words if word not in stpwords]\n",
    "  sent = ' '.join(lemmitized)\n",
    "  return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Ri99TQVMoHEg"
   },
   "outputs": [],
   "source": [
    "#Apply preprocessing\n",
    "train['question1'] =train['question1'].apply(preprocess)\n",
    "train['question2'] =train['question2'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "yNu_DueBwY3i",
    "outputId": "a217b3f0-4ce8-4609-8a52-a75ea31c683b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>step step guide invest share market india</td>\n",
       "      <td>step step guide invest share market</td>\n",
       "      <td>0</td>\n",
       "      <td>step step guide invest share market india step...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>story kohinoor koh noor diamond</td>\n",
       "      <td>would happen indian government stole kohinoor ...</td>\n",
       "      <td>0</td>\n",
       "      <td>story kohinoor koh noor diamond would happen i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>increase speed internet connection using vpn</td>\n",
       "      <td>internet speed increased hacking dns</td>\n",
       "      <td>0</td>\n",
       "      <td>increase speed internet connection using vpn i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>mentally lonely solve</td>\n",
       "      <td>find remainder math 23 24 math divided 24 23</td>\n",
       "      <td>0</td>\n",
       "      <td>mentally lonely solve find remainder math 23 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
       "      <td>fish would survive salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>one dissolve water quikly sugar salt methane c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>astrology capricorn sun cap moon cap rising say</td>\n",
       "      <td>triple capricorn sun moon ascendant capricorn say</td>\n",
       "      <td>1</td>\n",
       "      <td>astrology capricorn sun cap moon cap rising sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>13</td>\n",
       "      <td>14</td>\n",
       "      <td>buy tiago</td>\n",
       "      <td>keep childern active far phone video game</td>\n",
       "      <td>0</td>\n",
       "      <td>buy tiago keep childern active far phone video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>good geologist</td>\n",
       "      <td>great geologist</td>\n",
       "      <td>1</td>\n",
       "      <td>good geologist great geologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>use instead</td>\n",
       "      <td>use instead</td>\n",
       "      <td>0</td>\n",
       "      <td>use instead use instead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>motorola company hack charter motorolla dcx3400</td>\n",
       "      <td>hack motorola dcx3400 free internet</td>\n",
       "      <td>0</td>\n",
       "      <td>motorola company hack charter motorolla dcx340...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2          step step guide invest share market india   \n",
       "1   1     3     4                    story kohinoor koh noor diamond   \n",
       "2   2     5     6       increase speed internet connection using vpn   \n",
       "3   3     7     8                              mentally lonely solve   \n",
       "4   4     9    10  one dissolve water quikly sugar salt methane c...   \n",
       "5   5    11    12    astrology capricorn sun cap moon cap rising say   \n",
       "6   6    13    14                                          buy tiago   \n",
       "7   7    15    16                                     good geologist   \n",
       "8   8    17    18                                        use instead   \n",
       "9   9    19    20    motorola company hack charter motorolla dcx3400   \n",
       "\n",
       "                                           question2  is_duplicate  \\\n",
       "0                step step guide invest share market             0   \n",
       "1  would happen indian government stole kohinoor ...             0   \n",
       "2               internet speed increased hacking dns             0   \n",
       "3       find remainder math 23 24 math divided 24 23             0   \n",
       "4                      fish would survive salt water             0   \n",
       "5  triple capricorn sun moon ascendant capricorn say             1   \n",
       "6          keep childern active far phone video game             0   \n",
       "7                                    great geologist             1   \n",
       "8                                        use instead             0   \n",
       "9                hack motorola dcx3400 free internet             0   \n",
       "\n",
       "                                             combine  \n",
       "0  step step guide invest share market india step...  \n",
       "1  story kohinoor koh noor diamond would happen i...  \n",
       "2  increase speed internet connection using vpn i...  \n",
       "3  mentally lonely solve find remainder math 23 2...  \n",
       "4  one dissolve water quikly sugar salt methane c...  \n",
       "5  astrology capricorn sun cap moon cap rising sa...  \n",
       "6  buy tiago keep childern active far phone video...  \n",
       "7                     good geologist great geologist  \n",
       "8                            use instead use instead  \n",
       "9  motorola company hack charter motorolla dcx340...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate Question 1 & Question 2\n",
    "def concat(ser):\n",
    "  print(ser['question1'])\n",
    "  return 1\n",
    "train['combine'] = train.apply(lambda ser: ser['question1'] + \" \" + ser['question2'],axis=1)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "30WPiRB9FlHI"
   },
   "source": [
    "#### Convert Words into Vector\n",
    "\n",
    "Using tf-idf to assign how relevant words are in the questions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KipLu4QmoViN",
    "outputId": "3d092751-9e59-4ae3-f6c8-b9d39921cd71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404287, 50000)\n",
      "(384072, 50000) (20215, 50000)\n"
     ]
    }
   ],
   "source": [
    "cv = TfidfVectorizer(max_features=50000)#Word to Vectors using Tf-Idf\n",
    "\n",
    "#Take combine questions data as X\n",
    "X = cv.fit_transform(train['combine'])\n",
    "y = np.array(train['is_duplicate'])\n",
    "print(X.shape)\n",
    "\n",
    "#Tarin-Test Spilt\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.05)\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hILRi5S4AokT"
   },
   "outputs": [],
   "source": [
    "nb_model = MultinomialNB()#Training\n",
    "nb_model.fit(X_train,y_train)\n",
    "\n",
    "#Predictions\n",
    "y_pred_train = nb_model.predict(X_train)\n",
    "y_pred_test = nb_model.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gkhT6SwUwHSt",
    "outputId": "7ba8188f-b390-42f4-d014-d78e1c36c4fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7518225749338666 0.7419243136284936\n"
     ]
    }
   ],
   "source": [
    " \n",
    "accuracy_train = sum((y_pred_train == y_train).astype(int))/len(y_train)\n",
    "accuracy_test = sum((y_pred_test == y_test).astype(int))/len(y_test)\n",
    "print(accuracy_train,accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QRRwz7I3JJRr"
   },
   "source": [
    "We got 74% Accuracy, which is not very good for text classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8caSnoaJR2A"
   },
   "source": [
    "### BERT\n",
    "I used the \"Semantic Similarity with BERT\" code to solve this problem.<br>\n",
    "reference : https://keras.io/examples/nlp/semantic_similarity_with_bert/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "T8JzKW4bBuT4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==2.11.0\n",
      "  Using cached transformers-2.11.0-py3-none-any.whl (674 kB)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /opt/conda/lib/python3.6/site-packages (from transformers==2.11.0) (0.7)\n",
      "Requirement already satisfied: sacremoses in /opt/conda/lib/python3.6/site-packages (from transformers==2.11.0) (0.0.38)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.6/site-packages (from transformers==2.11.0) (20.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.6/site-packages (from transformers==2.11.0) (4.45.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.6/site-packages (from transformers==2.11.0) (2020.4.4)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from transformers==2.11.0) (2.23.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.6/site-packages (from transformers==2.11.0) (3.0.10)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from transformers==2.11.0) (1.18.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.6/site-packages (from transformers==2.11.0) (0.1.85)\n",
      "Collecting tokenizers==0.7.0\n",
      "  Using cached tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8 MB)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==2.11.0) (1.14.0)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==2.11.0) (0.14.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.6/site-packages (from sacremoses->transformers==2.11.0) (7.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.6/site-packages (from packaging->transformers==2.11.0) (2.4.7)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.11.0) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.11.0) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.11.0) (1.25.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->transformers==2.11.0) (2.9)\n",
      "Installing collected packages: tokenizers, transformers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.5.2\n",
      "    Uninstalling tokenizers-0.5.2:\n",
      "      Successfully uninstalled tokenizers-0.5.2\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 2.8.0\n",
      "    Uninstalling transformers-2.8.0:\n",
      "      Successfully uninstalled transformers-2.8.0\n",
      "Successfully installed tokenizers-0.7.0 transformers-2.11.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "!pip install transformers==2.11.0\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Mz9AA6PaNLig"
   },
   "outputs": [],
   "source": [
    "max_length = 128  # Maximum length of input sentence to the model.\n",
    "batch_size = 4\n",
    "epochs = 2\n",
    "path = \"quora-question-pairs\"\n",
    "# Labels in our dataset.\n",
    "labels = [1,0]\n",
    "#1 : Non Duplicate\n",
    "#0 : Duplicate\n",
    "df = pd.read_csv(path+\"/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jqCjQXp7KYeE"
   },
   "source": [
    "#### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z5OjhdncStr-",
    "outputId": "3c9c603e-b9a6-4f8a-dd89-0967d56a72d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id              0\n",
      "qid1            0\n",
      "qid2            0\n",
      "question1       1\n",
      "question2       2\n",
      "is_duplicate    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Dropping Null values\n",
    "print(df.isnull().sum(axis=0))\n",
    "df.dropna(axis=0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 198
    },
    "id": "MyVkSGoNNaqY",
    "outputId": "0891bfe7-27c2-48ab-a11c-d3c1c7e50abe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>20</td>\n",
       "      <td>Motorola (company): Can I hack my Charter Moto...</td>\n",
       "      <td>How do I hack Motorola DCX3400 for free internet?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>Why do girls want to be friends with the guy t...</td>\n",
       "      <td>How do guys feel after rejecting a girl?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>Which is the best digital marketing institutio...</td>\n",
       "      <td>Which is the best digital marketing institute ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>73</td>\n",
       "      <td>74</td>\n",
       "      <td>I'm a 19-year-old. How can I improve my skills...</td>\n",
       "      <td>I am a 19 year old guy. How can I become a bil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>41</td>\n",
       "      <td>83</td>\n",
       "      <td>84</td>\n",
       "      <td>When can I expect my Cognizant confirmation mail?</td>\n",
       "      <td>When can I expect Cognizant confirmation mail?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  qid1  qid2                                          question1  \\\n",
       "9    9    19    20  Motorola (company): Can I hack my Charter Moto...   \n",
       "17  17    35    36  Why do girls want to be friends with the guy t...   \n",
       "19  19    39    40  Which is the best digital marketing institutio...   \n",
       "36  36    73    74  I'm a 19-year-old. How can I improve my skills...   \n",
       "41  41    83    84  When can I expect my Cognizant confirmation mail?   \n",
       "\n",
       "                                            question2  is_duplicate  \n",
       "9   How do I hack Motorola DCX3400 for free internet?             0  \n",
       "17           How do guys feel after rejecting a girl?             0  \n",
       "19  Which is the best digital marketing institute ...             0  \n",
       "36  I am a 19 year old guy. How can I become a bil...             0  \n",
       "41     When can I expect Cognizant confirmation mail?             0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create mask for train-test distribution\n",
    "mask = np.random.rand(len(df)) < 0.7\n",
    "train_df = df[mask]\n",
    "not_train = df[~mask]\n",
    "\n",
    "#create mask for val-test distribution\n",
    "mask = np.random.rand(len(not_train)) < 0.5\n",
    "test_df = not_train[mask]\n",
    "val_df = not_train[~mask]\n",
    "val_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_HYhifpvPWR4",
    "outputId": "2a3dc6f7-9890-4e09-e0c9-357b6f149b71"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total train samples : 282884\n",
      "Total validation samples: 60802\n",
      "Total test samples: 60601\n"
     ]
    }
   ],
   "source": [
    "# Shape of the data\n",
    "print(f\"Total train samples : {train_df.shape[0]}\")\n",
    "print(f\"Total validation samples: {val_df.shape[0]}\")\n",
    "print(f\"Total test samples: {test_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0P4qgJk-OrNg",
    "outputId": "c3a4705d-dcf1-4eba-b69a-a9f4ea315401"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Target Distribution\n",
      "0    178251\n",
      "1    104633\n",
      "Name: is_duplicate, dtype: int64\n",
      "Validation Target Distribution\n",
      "0    38343\n",
      "1    22459\n",
      "Name: is_duplicate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Target Distribution\")\n",
    "print(train_df.is_duplicate.value_counts())\n",
    "\n",
    "print(\"Validation Target Distribution\")\n",
    "print(val_df.is_duplicate.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4AU_fSSTp-W",
    "outputId": "ff6ca75b-9650-4ab9-9a91-bdc7256f1c0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape:(282884, 2)\n",
      "y_val.shape:(60802, 2)\n",
      "y_test.shape:(60601, 2)\n"
     ]
    }
   ],
   "source": [
    "#One hot encoding \n",
    "y_train = tf.keras.utils.to_categorical(train_df.is_duplicate, num_classes=2)\n",
    "print(f\"y_train.shape:{y_train.shape}\")\n",
    "\n",
    "y_val = tf.keras.utils.to_categorical(val_df.is_duplicate, num_classes=2)\n",
    "print(f\"y_val.shape:{y_val.shape}\")\n",
    "\n",
    "y_test = tf.keras.utils.to_categorical(test_df.is_duplicate, num_classes=2)\n",
    "print(f\"y_test.shape:{y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_CjpwdrKSnG"
   },
   "source": [
    "#### Custom Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "p83ejnitUOmx"
   },
   "outputs": [],
   "source": [
    "class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"Generates batches of data.\n",
    "\n",
    "    Args:\n",
    "        sentence_pairs: Array of premise and hypothesis input sentences.\n",
    "        labels: Array of labels.\n",
    "        batch_size: Integer batch size.\n",
    "        shuffle: boolean, whether to shuffle the data.\n",
    "        include_targets: boolean, whether to incude the labels.\n",
    "\n",
    "    Returns:\n",
    "        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n",
    "        (or just `[input_ids, attention_mask, `token_type_ids]`\n",
    "         if `include_targets=False`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sentence_pairs,\n",
    "        labels,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        include_targets=True,\n",
    "    ):\n",
    "        self.sentence_pairs = sentence_pairs\n",
    "        self.labels = labels\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.include_targets = include_targets\n",
    "        \n",
    "        # Load our BERT Tokenizer to encode the text.\n",
    "        # We will use base-base-uncased pretrained model.\n",
    "        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n",
    "            \"bert-base-uncased\", do_lower_case=True\n",
    "        )\n",
    "        self.indexes = np.arange(len(self.sentence_pairs))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch.\n",
    "        return len(self.sentence_pairs) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieves the batch of index.\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        sentence_pairs = self.sentence_pairs[indexes]\n",
    "\n",
    "        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n",
    "        # encoded together and separated by [SEP] token.\n",
    "        encoded = self.tokenizer.batch_encode_plus(\n",
    "            sentence_pairs.tolist(),\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            pad_to_max_length=True,\n",
    "            return_tensors=\"tf\",\n",
    "        )\n",
    "\n",
    "        # Convert batch of encoded features to numpy array.\n",
    "        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
    "        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
    "        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
    "\n",
    "        # Set to true if data generator is used for training/validation.\n",
    "        if self.include_targets:\n",
    "            labels = np.array(self.labels[indexes], dtype=\"int32\")\n",
    "            return [input_ids, attention_masks, token_type_ids], labels\n",
    "        else:\n",
    "            return [input_ids, attention_masks, token_type_ids]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle indexes after each epoch if shuffle is set to True.\n",
    "        if self.shuffle:\n",
    "            np.random.RandomState(42).shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7SenBveKsJm"
   },
   "source": [
    "#### Build The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l-AaVCJnVZY4",
    "outputId": "25af4675-e9ed-4a24-fa5f-98213aacf079"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "Strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x7f6742d8cf98>\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_masks (InputLayer)    [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_type_ids (InputLayer)     [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     ((None, 128, 768), ( 109482240   input_ids[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 128, 128)     426496      tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 256)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            514         dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 109,909,250\n",
      "Trainable params: 427,010\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model under a distribution strategy scope.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    # Encoded token ids from BERT tokenizer.\n",
    "    input_ids = tf.keras.layers.Input(\n",
    "        shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n",
    "    )\n",
    "    # Attention masks indicates to the model which tokens should be attended to.\n",
    "    attention_masks = tf.keras.layers.Input(\n",
    "        shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n",
    "    )\n",
    "    # Token type ids are binary masks identifying different sequences in the model.\n",
    "    token_type_ids = tf.keras.layers.Input(\n",
    "        shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n",
    "    )\n",
    "    # Loading pretrained BERT model.\n",
    "    bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    # Freeze the BERT model to reuse the pretrained features without modifying them.\n",
    "    bert_model.trainable = False\n",
    "\n",
    "    sequence_output, pooled_output = bert_model(\n",
    "        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n",
    "    )\n",
    "    # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n",
    "    bi_lstm = tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64, return_sequences=True))(sequence_output)\n",
    "    \n",
    "    # Applying hybrid pooling approach to bi_lstm sequence output.\n",
    "    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n",
    "    max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n",
    "    concat = tf.keras.layers.concatenate([avg_pool, max_pool])\n",
    "    dropout = tf.keras.layers.Dropout(0.3)(concat)\n",
    "    output = tf.keras.layers.Dense(2, activation=\"softmax\")(dropout)\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"acc\"],\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"Strategy: {strategy}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gGgQnzm5Kyu0"
   },
   "source": [
    "#### Create train and validation data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "79c51534eee347cb8061845c9598a8b1",
      "6b2745d462b24a1581247aaf087c8c12",
      "3e82aee461924e348ed361f0d966d230",
      "404a3f9eb80649a49d905e38a31472df",
      "9f1f543b8caf4b56ad8ebc212a4b9bcf",
      "81845e5c98d24f26b1e349124db910bb",
      "603ab12269b545c8b16c6cbd2a679b22",
      "bc21b8ed339b486ea8d7e21ad0098577"
     ]
    },
    "id": "u0YYkAdWVzx9",
    "outputId": "aff7714f-cc9c-4bbe-ddce-2a8544fb6147"
   },
   "outputs": [],
   "source": [
    "train_data = BertSemanticDataGenerator(\n",
    "    train_df[[\"question1\", \"question2\"]].values.astype(\"str\"),\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "val_data = BertSemanticDataGenerator(\n",
    "    val_df[[\"question1\", \"question2\"]].values.astype(\"str\"),\n",
    "    y_val,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klXsKJVkK5ng"
   },
   "source": [
    "#### Train the model\n",
    "Training is done only for the top layers to perform \"feature extraction\", which will allow the model to use the representations of the pretrained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dtddz2yOYh7J",
    "outputId": "b6a0622f-6697-4762-cd60-0cb379dcae70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 70721 steps, validate for 15200 steps\n",
      "Epoch 1/2\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "70720/70721 [============================>.] - ETA: 0s - loss: 0.4011 - acc: 0.8064INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "70721/70721 [==============================] - 4470s 63ms/step - loss: 0.4011 - acc: 0.8064 - val_loss: 0.3479 - val_acc: 0.8381\n",
      "Epoch 2/2\n",
      "70721/70721 [==============================] - 4451s 63ms/step - loss: 0.3624 - acc: 0.8299 - val_loss: 0.3365 - val_acc: 0.8456\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=epochs,\n",
    "     use_multiprocessing=True,\n",
    "    workers=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEbnhEX1CWRg"
   },
   "source": [
    "#### Fine Tuning\n",
    "\n",
    "Now BERT model has knowledge of Language & Context now we can unfreeze the BERT pretrained weights & retrain using very low learning rate to solve actual NLP problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OPYy3UMICQN_",
    "outputId": "1b7904c1-e300-44ad-b974-87aecd58f16a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_masks (InputLayer)    [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "token_type_ids (InputLayer)     [(None, 128)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model (TFBertModel)     ((None, 128, 768), ( 109482240   input_ids[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 128, 128)     426496      tf_bert_model[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d (Globa (None, 128)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d (GlobalMax (None, 128)          0           bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 256)          0           global_average_pooling1d[0][0]   \n",
      "                                                                 global_max_pooling1d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "dropout_37 (Dropout)            (None, 256)          0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 2)            514         dropout_37[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 109,909,250\n",
      "Trainable params: 109,909,250\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.trainable = True\n",
    "# Recompile the model to make the change effective.\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t-OHjA9aYwn7",
    "outputId": "93de2707-298a-497a-f6da-909a02635aed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 70721 steps, validate for 15200 steps\n",
      "Epoch 1/2\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n",
      "70721/70721 [==============================] - 6920s 98ms/step - loss: 0.3184 - accuracy: 0.8580 - val_loss: 0.2690 - val_accuracy: 0.8848\n",
      "Epoch 2/2\n",
      "70721/70721 [==============================] - 6891s 97ms/step - loss: 0.2362 - accuracy: 0.9017 - val_loss: 0.2458 - val_accuracy: 0.8969\n"
     ]
    }
   ],
   "source": [
    "import gc; \n",
    "gc.collect()\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=val_data,\n",
    "    epochs=epochs,\n",
    "    use_multiprocessing=True,\n",
    "    workers=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLjeRqvWMbyx"
   },
   "source": [
    "Model was trained for 4-5 hours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8sYaB-wCjDp"
   },
   "source": [
    "#### Evaluate on Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l1jV1ZuOChKi",
    "outputId": "675df007-775f-4781-9d6c-66a4ec8160a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "15150/15150 [==============================] - 633s 42ms/step - loss: 0.2438 - accuracy: 0.8969\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.24381618442934172, 0.8969142]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = BertSemanticDataGenerator(\n",
    "    test_df[[\"question1\", \"question2\"]].values.astype(\"str\"),\n",
    "    y_test,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "model.evaluate(test_data, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mS6T3PSpLp5k"
   },
   "source": [
    "We Got 90% Accuracy on Test Dataset which is far better than Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "1uUn9RU2DcfB"
   },
   "outputs": [],
   "source": [
    "def check_similarity(sentence1, sentence2):\n",
    "  sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n",
    "  test_data = BertSemanticDataGenerator(\n",
    "      sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n",
    "  )\n",
    "\n",
    "  proba = model.predict(test_data)[0]\n",
    "  idx = np.argmax(proba)\n",
    "  proba = f\"{proba[idx]: .2f}%\"\n",
    "  pred = labels[idx]\n",
    "  return pred, proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ioYNFI58LfJL"
   },
   "source": [
    "#### Try the custom Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XTA9J9gxOPtR",
    "outputId": "bd203aee-5ae4-4c2e-c47c-b96ac6fe0c4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is wrong with today's education system?\n",
      "What are the things going wrong in our education system?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, ' 0.80%')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.random.randint(0,500) \n",
    "#Duplicate Questions\n",
    "q1 = test_df[test_df[\"is_duplicate\"] == 1].iloc[ind]['question1']\n",
    "q2 = test_df[test_df[\"is_duplicate\"] == 1].iloc[ind]['question2']\n",
    "print(q1+\"\\n\"+q2)\n",
    "check_similarity(q1,q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-NhfBIwGOZ2_",
    "outputId": "5fbddd45-b31f-459a-81f1-fd07cedcbe54"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What do you think of this blog?\n",
      "What do you think about this blog forfishingvideos.blogspot.com?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, ' 1.00%')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = np.random.randint(0,500)\n",
    "#Non-Duplicate Questions\n",
    "q1 = test_df[test_df[\"is_duplicate\"] == 0].iloc[ind]['question1']\n",
    "q2 = test_df[test_df[\"is_duplicate\"] == 0].iloc[ind]['question2']\n",
    "print(q1+\"\\n\"+q2)\n",
    "check_similarity(q1,q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1rr6dvgSmVL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Quora Questions Pairs.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "10ba28fbdf384e6d4de392f69dd3305a14cb019e470236e2e7bb3ed0070ecfd8"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3e82aee461924e348ed361f0d966d230": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_81845e5c98d24f26b1e349124db910bb",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9f1f543b8caf4b56ad8ebc212a4b9bcf",
      "value": 231508
     }
    },
    "404a3f9eb80649a49d905e38a31472df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bc21b8ed339b486ea8d7e21ad0098577",
      "placeholder": "​",
      "style": "IPY_MODEL_603ab12269b545c8b16c6cbd2a679b22",
      "value": " 232k/232k [00:00&lt;00:00, 1.83MB/s]"
     }
    },
    "603ab12269b545c8b16c6cbd2a679b22": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6b2745d462b24a1581247aaf087c8c12": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "79c51534eee347cb8061845c9598a8b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3e82aee461924e348ed361f0d966d230",
       "IPY_MODEL_404a3f9eb80649a49d905e38a31472df"
      ],
      "layout": "IPY_MODEL_6b2745d462b24a1581247aaf087c8c12"
     }
    },
    "81845e5c98d24f26b1e349124db910bb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9f1f543b8caf4b56ad8ebc212a4b9bcf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "bc21b8ed339b486ea8d7e21ad0098577": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
