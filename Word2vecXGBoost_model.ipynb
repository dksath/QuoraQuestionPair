{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gensim\n",
    "from pyemd import emd\n",
    "from fuzzywuzzy import fuzz\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm_notebook\n",
    "from nltk import word_tokenize\n",
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
    "from nltk import word_tokenize\n",
    "stop_words = stopwords.words('english')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /home/jovyan/.cache/pip/wheels/f9/f0/23/aefbdde40e915c67830ebecb55be2344a8b6e95fe3ce3ccf96/pyemd-0.5.1-cp36-cp36m-linux_x86_64.whl\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.9.0 in /opt/conda/lib/python3.6/site-packages (from pyemd) (1.18.2)\n",
      "Installing collected packages: pyemd\n",
      "Successfully installed pyemd-0.5.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyemd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wmd(q1, q2):\n",
    "    q1 = str(q1).lower().split()\n",
    "    q2 = str(q2).lower().split()\n",
    "    stop_words = stopwords.words('english')\n",
    "    q1 = [w for w in q1 if w not in stop_words]\n",
    "    q2 = [w for w in q2 if w not in stop_words]\n",
    "    return model.wmdistance(q1, q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_wmd(q1, q2):\n",
    "    q1 = str(q1).lower().split()\n",
    "    q2 = str(q2).lower().split()\n",
    "    stop_words = stopwords.words('english')\n",
    "    q1 = [w for w in q1 if w not in stop_words]\n",
    "    q2 = [w for w in q2 if w not in stop_words]\n",
    "    return norm_model.wmdistance(q1, q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2vec(s):\n",
    "    words = str(s).lower()\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(model[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASIC FEATURES\n",
    "df['len_q1'] = df.question1.apply(lambda x: len(str(x)))\n",
    "df['len_q2'] = df.question2.apply(lambda x: len(str(x)))\n",
    "df['diff_len'] = df.len_q1 - df.len_q2\n",
    "df['len_char_q1'] = df.question1.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "df['len_char_q2'] = df.question2.apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "df['len_word_q1'] = df.question1.apply(lambda x: len(str(x).split()))\n",
    "df['len_word_q2'] = df.question2.apply(lambda x: len(str(x).split()))\n",
    "df['common_words'] = df.apply(lambda x: len(set(str(x['question1']).lower().split()).intersection(set(str(x['question2']).lower().split()))), axis=1)\n",
    "# FUZZY FEATURES\n",
    "df['fuzz_ratio'] = df.apply(lambda x: fuzz.ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "df['fuzz_partial_ratio'] = df.apply(lambda x: fuzz.partial_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "df['fuzz_partial_token_set_ratio'] = df.apply(lambda x: fuzz.partial_token_set_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "df['fuzz_partial_token_sort_ratio'] = df.apply(lambda x: fuzz.partial_token_sort_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "df['fuzz_token_set_ratio'] = df.apply(lambda x: fuzz.token_set_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "df['fuzz_token_sort_ratio'] = df.apply(lambda x: fuzz.token_sort_ratio(str(x['question1']), str(x['question2'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_char_q1</th>\n",
       "      <th>len_char_q2</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>len_word_q2</th>\n",
       "      <th>common_words</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>fuzz_partial_token_set_ratio</th>\n",
       "      <th>fuzz_partial_token_sort_ratio</th>\n",
       "      <th>fuzz_token_set_ratio</th>\n",
       "      <th>fuzz_token_sort_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>What is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>57</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>93</td>\n",
       "      <td>98</td>\n",
       "      <td>100</td>\n",
       "      <td>88</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>What is the story of Kohinoor (Koh-i-Noor) Dia...</td>\n",
       "      <td>What would happen if the Indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>-37</td>\n",
       "      <td>21</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>65</td>\n",
       "      <td>73</td>\n",
       "      <td>100</td>\n",
       "      <td>73</td>\n",
       "      <td>86</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  What is the step by step guide to invest in sh...   \n",
       "1   1     3     4  What is the story of Kohinoor (Koh-i-Noor) Dia...   \n",
       "\n",
       "                                           question2  is_duplicate  len_q1  \\\n",
       "0  What is the step by step guide to invest in sh...             0      66   \n",
       "1  What would happen if the Indian government sto...             0      51   \n",
       "\n",
       "   len_q2  diff_len  len_char_q1  len_char_q2  len_word_q1  len_word_q2  \\\n",
       "0      57         9           20           20           14           12   \n",
       "1      88       -37           21           29            8           13   \n",
       "\n",
       "   common_words  fuzz_ratio  fuzz_partial_ratio  fuzz_partial_token_set_ratio  \\\n",
       "0            10          93                  98                           100   \n",
       "1             4          65                  73                           100   \n",
       "\n",
       "   fuzz_partial_token_sort_ratio  fuzz_token_set_ratio  fuzz_token_sort_ratio  \n",
       "0                             88                   100                     93  \n",
       "1                             73                    86                     63  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vec Modeling (WORD2VEC FEATURES)\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "df['wmd'] = df.apply(lambda x: wmd(x['question1'], x['question2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalized Word2vec Modeling\n",
    "norm_model = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "norm_model.init_sims(replace=True)\n",
    "df['norm_wmd'] = df.apply(lambda x: norm_wmd(x['question1'], x['question2']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6e341938c304f78bb9463da471d157b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=404290.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:7: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f1844f7ac94b86a380405f1ac80db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=404290.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "question1_vectors = np.zeros((df.shape[0], 300))\n",
    "\n",
    "for i, q in enumerate(tqdm_notebook(df.question1.values)):\n",
    "    question1_vectors[i, :] = sent2vec(q)\n",
    "    \n",
    "question2_vectors  = np.zeros((df.shape[0], 300))\n",
    "for i, q in enumerate(tqdm_notebook(df.question2.values)):\n",
    "    question2_vectors[i, :] = sent2vec(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/scipy/spatial/distance.py:720: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  dist = 1.0 - uv / np.sqrt(uu * vv)\n",
      "/opt/conda/lib/python3.6/site-packages/scipy/spatial/distance.py:1178: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return l1_diff.sum() / l1_sum.sum()\n"
     ]
    }
   ],
   "source": [
    "# DISTANCE MEASURES (WORD2VEC FEATURES)\n",
    "df['cosine_distance'] = [cosine(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors), np.nan_to_num(question2_vectors))]\n",
    "df['cityblock_distance'] = [cityblock(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors), np.nan_to_num(question2_vectors))]\n",
    "df['jaccard_distance'] = [jaccard(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors), np.nan_to_num(question2_vectors))]\n",
    "df['canberra_distance'] = [canberra(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors), np.nan_to_num(question2_vectors))]\n",
    "df['euclidean_distance'] = [euclidean(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors), np.nan_to_num(question2_vectors))]\n",
    "df['minkowski_distance'] = [minkowski(x, y, 3) for (x, y) in zip(np.nan_to_num(question1_vectors), np.nan_to_num(question2_vectors))]\n",
    "df['braycurtis_distance'] = [braycurtis(x, y) for (x, y) in zip(np.nan_to_num(question1_vectors), np.nan_to_num(question2_vectors))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    255027\n",
       "1    149263\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['is_duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                  0\n",
       "qid1                                0\n",
       "qid2                                0\n",
       "question1                           1\n",
       "question2                           2\n",
       "is_duplicate                        0\n",
       "len_q1                              0\n",
       "len_q2                              0\n",
       "diff_len                            0\n",
       "len_char_q1                         0\n",
       "len_char_q2                         0\n",
       "len_word_q1                         0\n",
       "len_word_q2                         0\n",
       "common_words                        0\n",
       "fuzz_ratio                          0\n",
       "fuzz_partial_ratio                  0\n",
       "fuzz_partial_token_set_ratio        0\n",
       "fuzz_partial_token_sort_ratio       0\n",
       "fuzz_token_set_ratio                0\n",
       "fuzz_token_sort_ratio               0\n",
       "wmd                                 0\n",
       "norm_wmd                            0\n",
       "cosine_distance                  1775\n",
       "cityblock_distance                  0\n",
       "jaccard_distance                    0\n",
       "canberra_distance                   0\n",
       "euclidean_distance                  0\n",
       "minkowski_distance                  0\n",
       "braycurtis_distance               522\n",
       "dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['question1', 'question2'], axis=1, inplace=True)\n",
    "df = df[pd.notnull(df['cosine_distance'])]\n",
    "df = df[pd.notnull(df['jaccard_distance'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            id    qid1    qid2  is_duplicate  len_q1  len_q2  diff_len  \\\n",
      "0            0       1       2             0      66      57         9   \n",
      "1            1       3       4             0      51      88       -37   \n",
      "2            2       5       6             0      73      59        14   \n",
      "3            3       7       8             0      50      65       -15   \n",
      "4            4       9      10             0      76      39        37   \n",
      "...        ...     ...     ...           ...     ...     ...       ...   \n",
      "404285  404285  433578  379845             0      85      79         6   \n",
      "404286  404286   18840  155606             1      41      42        -1   \n",
      "404287  404287  537928  537929             0      17      17         0   \n",
      "404288  404288  537930  537931             0      94     127       -33   \n",
      "404289  404289  537932  537933             0      37      45        -8   \n",
      "\n",
      "        len_char_q1  len_char_q2  len_word_q1  ...  fuzz_token_sort_ratio  \\\n",
      "0                20           20           14  ...                     93   \n",
      "1                21           29            8  ...                     63   \n",
      "2                25           24           14  ...                     63   \n",
      "3                19           26           11  ...                     24   \n",
      "4                25           18           13  ...                     47   \n",
      "...             ...          ...          ...  ...                    ...   \n",
      "404285           24           24           14  ...                     88   \n",
      "404286           17           13            8  ...                     69   \n",
      "404287           11           11            4  ...                     75   \n",
      "404288           26           27           17  ...                     35   \n",
      "404289           17           19            8  ...                     90   \n",
      "\n",
      "             wmd  norm_wmd  cosine_distance  cityblock_distance  \\\n",
      "0       0.217555  0.217555         0.068972            5.081614   \n",
      "1       1.368796  1.368796         0.512164           14.195119   \n",
      "2       0.639209  0.639209         0.222009            9.055989   \n",
      "3       1.263720  1.263720         0.650411           15.987437   \n",
      "4       1.240908  1.240908         0.369993           12.103178   \n",
      "...          ...       ...              ...                 ...   \n",
      "404285  0.227233  0.227233         0.131646            7.122625   \n",
      "404286  0.590033  0.590033         0.129039            7.146889   \n",
      "404287  1.382975  1.382975         0.069016            5.065351   \n",
      "404288  1.313263  1.313263         0.708233           16.438430   \n",
      "404289  0.000000  0.000000         0.000000            0.000000   \n",
      "\n",
      "        jaccard_distance  canberra_distance  euclidean_distance  \\\n",
      "0                    1.0          94.023324            0.371408   \n",
      "1                    1.0         177.588090            1.012091   \n",
      "2                    1.0         135.988707            0.666346   \n",
      "3                    1.0         192.237828            1.140536   \n",
      "4                    1.0         161.408435            0.860225   \n",
      "...                  ...                ...                 ...   \n",
      "404285               1.0         118.479153            0.513120   \n",
      "404286               1.0         119.485637            0.508014   \n",
      "404287               1.0          91.936365            0.371527   \n",
      "404288               1.0         194.867266            1.190154   \n",
      "404289               0.0           0.000000            0.000000   \n",
      "\n",
      "        minkowski_distance  braycurtis_distance  \n",
      "0                 0.168999             0.186557  \n",
      "1                 0.455910             0.592655  \n",
      "2                 0.307828             0.342306  \n",
      "3                 0.506028             0.692421  \n",
      "4                 0.382770             0.480633  \n",
      "...                    ...                  ...  \n",
      "404285            0.231429             0.262434  \n",
      "404286            0.226945             0.263738  \n",
      "404287            0.170819             0.182876  \n",
      "404288            0.540202             0.737343  \n",
      "404289            0.000000             0.000000  \n",
      "\n",
      "[404290 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix  \n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns != 'is_duplicate']\n",
    "y = df.loc[:, df.columns == 'is_duplicate']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/cudf/utils/cudautils.py:7: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.numpy_support', please update to use 'numba.np.numpy_support' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba import cuda, numpy_support\n",
      "/opt/conda/lib/python3.6/site-packages/cudf/utils/applyutils.py:7: NumbaDeprecationWarning: \u001b[1mAn import was requested from a module that has moved location.\n",
      "Import requested from: 'numba.utils', please update to use 'numba.core.utils' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.\u001b[0m\n",
      "  from numba.utils import exec_, pysignature\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10972  1734]\n",
      " [ 1984  5525]]\n",
      "Accuracy 0.8160771704180064\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.86      0.86     12706\n",
      "           1       0.76      0.74      0.75      7509\n",
      "\n",
      "    accuracy                           0.82     20215\n",
      "   macro avg       0.80      0.80      0.80     20215\n",
      "weighted avg       0.82      0.82      0.82     20215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRAIN XGBOOST MODEL & PREDICT\n",
    "import xgboost as xgb\n",
    "\n",
    "model = xgb.XGBClassifier(max_depth=50, n_estimators=80, learning_rate=0.1, colsample_bytree=.7, gamma=0, reg_alpha=4, objective='binary:logistic', eta=0.3, silent=1, subsample=0.8).fit(X_train, y_train.values.ravel()) \n",
    "prediction = model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, prediction)  \n",
    "print(cm)  \n",
    "print('Accuracy', accuracy_score(y_test, prediction))\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        is_duplicate\n",
      "284713             0\n",
      "66021              0\n",
      "192943             0\n",
      "387513             0\n",
      "119525             1\n",
      "...              ...\n",
      "359783             0\n",
      "358083             0\n",
      "152315             1\n",
      "117952             1\n",
      "305711             0\n",
      "\n",
      "[384075 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
